{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff4ec07e",
   "metadata": {},
   "source": [
    "### Length_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "924825d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_penalty_answer(pred, truth, ratio=1.3):\n",
    "    pred_len = len(pred.split())\n",
    "    truth_len = len(truth.split())\n",
    "    max_ok = round(truth_len * ratio) # mở rộng biên độ chấp nhận\n",
    "    \n",
    "    if pred_len <= max_ok:\n",
    "        return 1.0\n",
    "    else:\n",
    "        excess_ratio = (pred_len - max_ok) / truth_len\n",
    "        return - min(excess_ratio, 1.0)\n",
    "\n",
    "def length_penalty_explanation(pred, truth, ratio=1.2):\n",
    "    pred_len = len(pred.split())\n",
    "    truth_len = len(truth.split())\n",
    "    min_ok = max(5, int(truth_len * 0.7)) # mở rộng biên độ chấp nhận\n",
    "    max_ok = round(truth_len * ratio) # mở rộng biên độ chấp nhận\n",
    "    \n",
    "    if min_ok <= pred_len <= max_ok:\n",
    "        return 1.0\n",
    "    elif pred_len < min_ok:\n",
    "        return -0.5\n",
    "    else:\n",
    "        excess_ratio = (pred_len - max_ok) / truth_len\n",
    "        return - min(excess_ratio, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbdcd642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "-1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "-0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(length_penalty_answer(\"Đỏ\", \"Đỏ\"))      \n",
    "print(length_penalty_answer(\"Đỏ\", \"Màu đỏ\"))  \n",
    "print(length_penalty_answer(\"Màu đỏ\", \"Đỏ\"))  \n",
    "print(length_penalty_answer(\"Màu đỏ sáng\", \"Màu đỏ\"))  \n",
    "print(length_penalty_answer(\"Đỏ\", \"Màu đỏ tươi\"))  \n",
    "print(length_penalty_answer(\"Màu đỏ tươi rực\", \"Màu đỏ tươi\"))  \n",
    "print(length_penalty_answer(\"Màu đỏ tươi rực rỡ\", \"Màu đỏ tươi\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a14ec26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "-1.0\n",
      "-0.5\n",
      "-0.5\n",
      "-0.5\n",
      "1.0\n",
      "-0.5\n"
     ]
    }
   ],
   "source": [
    "print(length_penalty_explanation(\"Rất rõ ràng bức ảnh có hai con chó màu đen lớn đang đứng cạnh nhau\", \"Ảnh có hai con chó\")) \n",
    "print(length_penalty_explanation(\"Bức ảnh này có hai con chó màu đen ở giữa công viên vào buổi sáng rất đẹp\", \"Hai con chó màu đen\")) \n",
    "print(length_penalty_explanation(\"Có hai con chó\", \"Có hai con chó màu đen đang ở giữa ảnh vào buổi sáng\")) \n",
    "print(length_penalty_explanation(\"Hai con chó ở giữa\", \"Có hai con chó màu đen đang ở giữa ảnh vào buổi sáng\")) \n",
    "print(length_penalty_explanation(\"Có hai con chó màu đen\", \"Có hai con chó màu đen đang ở giữa ảnh vào buổi sáng\")) \n",
    "print(length_penalty_explanation(\"Có hai con chó màu đen đang ở trên cỏ công viên\", \"Có hai con chó màu đen đang ở giữa ảnh vào buổi sáng\")) \n",
    "print(length_penalty_explanation(\"Hai con chó\", \"Có hai con chó màu đen đang ở giữa ảnh vào buổi sáng\")) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e757925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_penalty_explanation(pred, truth, ratio=1.2, sentence_penalty_weight=0.3):\n",
    "    \"\"\"\n",
    "    Penalty function với kiểm soát số câu:\n",
    "    - Nếu pred có >= 2 câu (phân tách bởi '.' hoặc ',') -> phạt dựa trên số câu\n",
    "    - Nếu pred chỉ 1 câu -> kiểm tra độ dài như bình thường\n",
    "    \n",
    "    Args:\n",
    "        pred: Câu prediction\n",
    "        truth: Câu ground truth\n",
    "        ratio: Tỷ lệ độ dài tối đa cho phép\n",
    "        sentence_penalty_weight: Trọng số phạt cho mỗi câu thừa (mặc định 0.3)\n",
    "    \n",
    "    Returns:\n",
    "        float: 1.0 (ok), -0.5 (quá ngắn), hoặc giá trị âm (quá dài/nhiều câu)\n",
    "    \"\"\"\n",
    "    # Tách câu dựa trên dấu '.' hoặc ',' (loại bỏ câu rỗng)\n",
    "    import re\n",
    "    pred_sentences = [s.strip() for s in re.split(r'[.,]', pred) if s.strip()]\n",
    "    truth_sentences = [s.strip() for s in re.split(r'[.,]', truth) if s.strip()]\n",
    "    \n",
    "    num_pred_sentences = len(pred_sentences)\n",
    "    num_truth_sentences = len(truth_sentences)\n",
    "    \n",
    "    # Kiểm tra số câu: Nếu pred có >= 2 câu mà truth chỉ 1 câu -> phạt\n",
    "    if num_truth_sentences == 1 and num_pred_sentences >= 2:\n",
    "        # Phạt càng nặng khi gen càng nhiều câu\n",
    "        # Ví dụ: 2 câu -> -0.3, 3 câu -> -0.6, 4 câu -> -0.9, 5+ câu -> -1.0\n",
    "        excess_sentences = num_pred_sentences - 1\n",
    "        penalty = -min(excess_sentences * sentence_penalty_weight, 1.0)\n",
    "        return penalty\n",
    "    \n",
    "    # Nếu số câu hợp lệ -> kiểm tra độ dài từ\n",
    "    pred_len = len(pred.split())\n",
    "    truth_len = len(truth.split())\n",
    "    min_ok = max(5, int(truth_len * 0.7))\n",
    "    max_ok = round(truth_len * ratio)\n",
    "    \n",
    "    if min_ok <= pred_len <= max_ok:\n",
    "        return 1.0\n",
    "    elif pred_len < min_ok:\n",
    "        return -0.5\n",
    "    else:\n",
    "        excess_ratio = (pred_len - max_ok) / truth_len\n",
    "        return -min(excess_ratio, 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5e1b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 câu OK: -0.5\n",
      "2 câu: -0.3\n",
      "3 câu: -0.6\n",
      "5 câu: -1.0\n",
      "1 câu ngắn: -0.5\n"
     ]
    }
   ],
   "source": [
    "truth = \"Đây là một câu ground truth.\"\n",
    "\n",
    "# Case 1: Predict 1 câu, độ dài OK\n",
    "pred1 = \"Đây là câu trả lời phù hợp với độ dài.\"\n",
    "print(f\"1 câu OK: {length_penalty_explanation(pred1, truth)}\") -.05\n",
    "\n",
    "# Case 2: Predict 2 câu -> bị phạt\n",
    "pred2 = \"Đây là câu đầu tiên. Đây là câu thứ hai.\"\n",
    "print(f\"2 câu: {length_penalty_explanation(pred2, truth)}\")  # -0.3\n",
    "\n",
    "# Case 3: Predict 3 câu -> phạt nặng hơn\n",
    "pred3 = \"Câu một. Câu hai. Câu ba.\"\n",
    "print(f\"3 câu: {length_penalty_explanation(pred3, truth)}\")  # -0.6\n",
    "\n",
    "# Case 4: Predict 5 câu -> phạt tối đa\n",
    "pred4 = \"Câu 1. Câu 2. Câu 3. Câu 4. Câu 5.\"\n",
    "print(f\"5 câu: {length_penalty_explanation(pred4, truth)}\")  # -1.0\n",
    "\n",
    "# Case 5: Predict 1 câu nhưng quá ngắn\n",
    "pred5 = \"Ngắn quá.\"\n",
    "print(f\"1 câu ngắn: {length_penalty_explanation(pred5, truth)}\")  # -0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faa4663",
   "metadata": {},
   "source": [
    "### Rough L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7679d918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE-L: 0.1667\n",
      "Individual scores: [0.  0.  0.5]\n"
     ]
    }
   ],
   "source": [
    "from pycocoevalcap.rouge.rouge import Rouge\n",
    "\n",
    "def rouge_l_batch_reward(predictions_list, ground_truths_list):\n",
    "    gts = {}\n",
    "    res = {}\n",
    "    \n",
    "    for idx, (pred, truth) in enumerate(zip(predictions_list, ground_truths_list)):\n",
    "        sample_id = f'sample_{idx}'\n",
    "        gts[sample_id] = [truth.lower().strip()]\n",
    "        res[sample_id] = [pred.lower().strip()]\n",
    "    \n",
    "    scorer = Rouge()\n",
    "    avg_score, individual_scores = scorer.compute_score(gts, res)\n",
    "    return {\n",
    "        'avg_score': avg_score,\n",
    "        'individual_scores': individual_scores\n",
    "    }\n",
    "\n",
    "\n",
    "# Ví dụ\n",
    "predictions = [\n",
    "    \"Trượt Ván\",\n",
    "    \"Cuộn quay\",\n",
    "    \"Trượt sóng\",\n",
    "]\n",
    "\n",
    "ground_truths = [\n",
    "    \"lướt sóng\",\n",
    "    \"lướt sóng\",\n",
    "    \"lướt sóng\",\n",
    "]\n",
    "\n",
    "results = rouge_l_batch_reward(predictions, ground_truths)\n",
    "print(f\"Average ROUGE-L: {results['avg_score']:.4f}\")\n",
    "print(f\"Individual scores: {results['individual_scores']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7adbef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmetrics.text import BERTScore\n",
    "\n",
    "# 1. Khởi tạo BERTScore với PhoBERT\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "phobert_scorer = BERTScore(\n",
    "    model_name_or_path=\"/mnt/dataset1/pretrained_fm/vinai/phobert-base\",\n",
    "    num_layers=12,\n",
    "    rescale_with_baseline=False,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4c4b1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [\n",
    "    \"có 3 con mèo\",\n",
    "    \"Cuộn quay\",\n",
    "    \"Trượt sóng\",\n",
    "    \"ô tô\",\n",
    "    \"chú chó AKITA\"\n",
    "]\n",
    "\n",
    "ground_truths = [\n",
    "    \"có 5 con mèo\",\n",
    "    \"lướt sóng\",\n",
    "    \"lướt sóng\",\n",
    "    \"xe hơi\",\n",
    "    \"chó nhật bản\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff532239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: encoder.layer.*.attention.self.query.weight, encoder.layer.*.intermediate.dense.bias, encoder.layer.*.attention.output.dense.bias, encoder.layer.*.output.LayerNorm.bias, encoder.layer.*.attention.output.LayerNorm.weight, encoder.layer.*.output.dense.bias, embeddings.position_embeddings.weight, encoder.layer.*.output.dense.weight, encoder.layer.*.attention.self.query.bias, encoder.layer.*.output.LayerNorm.weight, encoder.layer.*.intermediate.dense.weight, embeddings.LayerNorm.bias, embeddings.token_type_embeddings.weight, pooler.dense.weight, encoder.layer.*.attention.output.LayerNorm.bias, encoder.layer.*.attention.self.key.bias, embeddings.word_embeddings.weight, embeddings.LayerNorm.weight, encoder.layer.*.attention.self.value.bias, encoder.layer.*.attention.output.dense.weight, pooler.dense.bias, encoder.layer.*.attention.self.value.weight, encoder.layer.*.attention.self.key.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Scores: [0.20858220756053925, 0.23071549832820892, 0.22716161608695984, 0.31682369112968445, 0.2283453345298767]\n"
     ]
    }
   ],
   "source": [
    "# Tính BERTScore\n",
    "phobert_scorer.reset() \n",
    "phobert_scorer.update(predictions, ground_truths)\n",
    "scores = phobert_scorer.compute()\n",
    "\n",
    "# Lấy kết quả (precision, recall, f1)\n",
    "f1_scores = scores['f1'].tolist()  # [0.85, 0.78] (ví dụ)\n",
    "print(f\"F1 Scores: {f1_scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6b031d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following layers were not sharded: encoder.layer.*.attention.self.query.weight, encoder.layer.*.intermediate.dense.bias, encoder.layer.*.attention.output.dense.bias, encoder.layer.*.output.LayerNorm.bias, encoder.layer.*.attention.output.LayerNorm.weight, encoder.layer.*.output.dense.bias, embeddings.position_embeddings.weight, encoder.layer.*.output.dense.weight, encoder.layer.*.attention.self.query.bias, encoder.layer.*.output.LayerNorm.weight, encoder.layer.*.intermediate.dense.weight, embeddings.LayerNorm.bias, embeddings.token_type_embeddings.weight, pooler.dense.weight, encoder.layer.*.attention.output.LayerNorm.bias, encoder.layer.*.attention.self.key.bias, embeddings.word_embeddings.weight, embeddings.LayerNorm.weight, encoder.layer.*.attention.self.value.bias, encoder.layer.*.attention.output.dense.weight, pooler.dense.bias, encoder.layer.*.attention.self.value.weight, encoder.layer.*.attention.self.key.weight\n",
      "The following layers were not sharded: encoder.layer.*.attention.self.query.weight, encoder.layer.*.intermediate.dense.bias, encoder.layer.*.attention.output.dense.bias, encoder.layer.*.output.LayerNorm.bias, encoder.layer.*.attention.output.LayerNorm.weight, encoder.layer.*.output.dense.bias, embeddings.position_embeddings.weight, encoder.layer.*.output.dense.weight, encoder.layer.*.attention.self.query.bias, encoder.layer.*.output.LayerNorm.weight, encoder.layer.*.intermediate.dense.weight, embeddings.LayerNorm.bias, embeddings.token_type_embeddings.weight, pooler.dense.weight, encoder.layer.*.attention.output.LayerNorm.bias, encoder.layer.*.attention.self.key.bias, embeddings.word_embeddings.weight, embeddings.LayerNorm.weight, encoder.layer.*.attention.self.value.bias, encoder.layer.*.attention.output.dense.weight, pooler.dense.bias, encoder.layer.*.attention.self.value.weight, encoder.layer.*.attention.self.key.weight\n",
      "The following layers were not sharded: encoder.layer.*.attention.self.query.weight, encoder.layer.*.intermediate.dense.bias, encoder.layer.*.attention.output.dense.bias, encoder.layer.*.output.LayerNorm.bias, encoder.layer.*.attention.output.LayerNorm.weight, encoder.layer.*.output.dense.bias, embeddings.position_embeddings.weight, encoder.layer.*.output.dense.weight, encoder.layer.*.attention.self.query.bias, encoder.layer.*.output.LayerNorm.weight, encoder.layer.*.intermediate.dense.weight, embeddings.LayerNorm.bias, embeddings.token_type_embeddings.weight, pooler.dense.weight, encoder.layer.*.attention.output.LayerNorm.bias, encoder.layer.*.attention.self.key.bias, embeddings.word_embeddings.weight, embeddings.LayerNorm.weight, encoder.layer.*.attention.self.value.bias, encoder.layer.*.attention.output.dense.weight, pooler.dense.bias, encoder.layer.*.attention.self.value.weight, encoder.layer.*.attention.self.key.weight\n",
      "The following layers were not sharded: encoder.layer.*.attention.self.query.weight, encoder.layer.*.intermediate.dense.bias, encoder.layer.*.attention.output.dense.bias, encoder.layer.*.output.LayerNorm.bias, encoder.layer.*.attention.output.LayerNorm.weight, encoder.layer.*.output.dense.bias, embeddings.position_embeddings.weight, encoder.layer.*.output.dense.weight, encoder.layer.*.attention.self.query.bias, encoder.layer.*.output.LayerNorm.weight, encoder.layer.*.intermediate.dense.weight, embeddings.LayerNorm.bias, embeddings.token_type_embeddings.weight, pooler.dense.weight, encoder.layer.*.attention.output.LayerNorm.bias, encoder.layer.*.attention.self.key.bias, embeddings.word_embeddings.weight, embeddings.LayerNorm.weight, encoder.layer.*.attention.self.value.bias, encoder.layer.*.attention.output.dense.weight, pooler.dense.bias, encoder.layer.*.attention.self.value.weight, encoder.layer.*.attention.self.key.weight\n",
      "The following layers were not sharded: encoder.layer.*.attention.self.query.weight, encoder.layer.*.intermediate.dense.bias, encoder.layer.*.attention.output.dense.bias, encoder.layer.*.output.LayerNorm.bias, encoder.layer.*.attention.output.LayerNorm.weight, encoder.layer.*.output.dense.bias, embeddings.position_embeddings.weight, encoder.layer.*.output.dense.weight, encoder.layer.*.attention.self.query.bias, encoder.layer.*.output.LayerNorm.weight, encoder.layer.*.intermediate.dense.weight, embeddings.LayerNorm.bias, embeddings.token_type_embeddings.weight, pooler.dense.weight, encoder.layer.*.attention.output.LayerNorm.bias, encoder.layer.*.attention.self.key.bias, embeddings.word_embeddings.weight, embeddings.LayerNorm.weight, encoder.layer.*.attention.self.value.bias, encoder.layer.*.attention.output.dense.weight, pooler.dense.bias, encoder.layer.*.attention.self.value.weight, encoder.layer.*.attention.self.key.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Scores: [0.8428176641464233, 0.345912367105484, 0.5009145140647888, 0.2785395681858063, 0.4424190819263458]\n"
     ]
    }
   ],
   "source": [
    "f1_scores = []\n",
    "for pred, ref in zip(predictions, ground_truths):\n",
    "    phobert_scorer.reset()\n",
    "    phobert_scorer.update([pred], [ref])\n",
    "    score = phobert_scorer.compute()\n",
    "    f1_scores.append(score['f1'].item())\n",
    "\n",
    "\n",
    "print(f\"F1 Scores: {f1_scores}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_vivqanle_grpo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
